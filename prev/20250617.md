# 英文を日本語に翻訳してください。
# 英文の最後に---とつけるのでそこまでを翻訳し、日本語の文章を続けてください。

Inner speech recognition using electroencephalography (EEG) signals
holds significant potential for advancing brain-computer interface (BCI),
particularly for individuals with speech impairments. However, decoding
inner speech from EEG data remains a challenging task due to the nonlinear, high-dimensional and temporal dynamic nature of neural signals.
In order to address the challenges, this study explores the application of
reservoir computing (RC), with a particular focus on bidirectional RC,
for the purpose of classifying inner speech from EEG signals. Contrary to
unidirectional RC, which processes data in a single time direction, bidirectional RC captures both past and future temporal dependencies. This
enhancement of the extraction of meaningful EEG features for classification is a significant contribution of this study. We evaluate the performance of both unidirectional and bidirectional RC architectures across
a range of reservoir sizes (400, 500, and 600 units) to identify the most
effective configuration for this task. Our results demonstrate that the
bidirectional RC consistently outperforms the unidirectional RC in terms
of accuracy and F1-score across all reservoir sizes, highlighting its superior
ability to extract comprehensive temporal features from EEG data. The
optimal performance is achieved by bidirectional RC with 600 reservoir
units, yielding an accuracy of 18.94% and an F1-score of 19.02%, which
surpasses all other configurations. In contrast, unidirectional RC with
600 units exhibits a lower accuracy of 17.22%. These findings underscore
the potential of bidirectional RC in EEG signals classification for inner
speech recognition, offering a promising direction for developing efficient
BCI with low-cost computation.

---
内的な音声認識を脳波（EEG）信号を用いて行うことは、特に音声障害を持つ個人にとって、脳-コンピュータインターフェース（BCI）の進歩に大きな可能性を秘めています。しかし、EEGデータから内的な音声をデコードすることは、神経信号の非線形、高次元、および時間的動態の特性により、依然として困難な課題です。この課題に対処するため、本研究では、リザーバーコンピューティング（RC）の応用を探求し、特に双方向RCに焦点を当て、EEG信号から内的な音声を分類することを目的としています。単方向RCとは異なり、双方向RCは過去と未来の時間的依存関係の両方を捉えます。この意味のあるEEG特徴の抽出の強化は、本研究の重要な貢献です。本研究では、単方向および双方向RCアーキテクチャの性能を、さまざまなリザーバーサイズ（400、500、および600ユニット）で評価し、このタスクに最も効果的な構成を特定します。結果は、双方向RCがすべてのリザーバーサイズで精度とF1スコアの点で単方向RCを一貫して上回ることを示しており、EEGデータから包括的な時間的特徴を抽出する優れた能力を強調しています。最適な性能は600ユニットの双方向RCによって達成され、精度18.94%、F1スコア19.02%となり、他のすべての構成を上回ります。一方で、600ユニットの単方向RCは精度17.22%と低い値を示しています。これらの結果は、内的な音声認識のためのEEG信号分類における双方向RCの可能性を強調し、低コスト計算で効率的なBCI開発への有望な方向性を提供します。
-

The fractured-vuggy carbonate reservoir comprises various types of storage and seepage
spaces, and is composed of multi-scale dissolution pores and fractures. The frequent changes to working
systems make the characteristics of water breakthrough complex, and the production data nonlinear and nonstationary, resulting in great difficulty in real-time prediction. Traditional production forecasting methods
only consider temporal correlations, neglecting the spatial correlations between production wells and local
geological features. In this paper, adopts a modular design approach that comprehensively considers the
spatiotemporal characteristics by abstracting each production well in the unit as a directed graph network
node. We establish a graph attention network module based on the connectivity between wells to simulate
fluid motion patterns and extract spatial features. To address the autocorrelation characteristics of the
production sequences, we use a self-attention mechanism module to capture the temporal dependency
relationships between production sequences. Finally, considering the fusion of spatiotemporal features,
a gating mechanism is designed to adaptively aggregate spatiotemporal characteristics produced by the
previous two modules, enabling dynamic production forecasting. We validate our proposed model using
real-world production data from the Tarim Basin in China. Our experimental results demonstrate the
superiority of the new model over existing production prediction models in fractured-vuggy carbonate
reservoirs.
---
破砕-空隙カーボネート貯留層は、さまざまなタイプの貯蔵および浸透空間を含み、マルチスケールの溶解孔と亀裂で構成されています。作業システムの頻繁な変更により、水の突破特性は複雑になり、生産データは非線形かつ非定常となり、リアルタイム予測が非常に困難になります。従来の生産予測方法は、時間的相関のみを考慮し、生産井と局所地質特性との間の空間的相関を無視しています。本論文では、各生産井を有向グラフネットワークノードとして抽象化することで、時空間特性を包括的に考慮したモジュール設計アプローチを採用します。井戸間の接続性に基づいて、流体の動きパターンをシミュレートし、空間的特徴を抽出するためのグラフアテンションネットワークモジュールを確立します。生産系列の自己相関特性に対処するため、自己注意メカニズムモジュールを使用して、生産系列間の時間的依存関係を捉えます。最後に、時空間特徴の融合を考慮して、前の2つのモジュールによって生成された時空間的特性を適応的に集約するゲーティングメカニズムを設計し、動的な生産予測を可能にします。提案したモデルを中国のタリム盆地からの実際の生産データを使用して検証します。実験結果は、破砕-空隙カーボネート貯留層における既存の生産予測モデルに対して、新しいモデルの優位性を示しています。
---

Graph reservoir computing (GraphRC) gains increasing attention by virtue of its high training efficiency. However, since GraphRC is developed without knowledge of its internal mechanism, it cannot be fully trusted to deploy in practice. Although there are some existing approaches that can be extended to interpret GraphRC, the specific role played by each neuron (i.e., reservoir node) of GraphRC is far less explored. To address this issue, the latent short-term memory property of each reservoir node of GraphRC is qualitatively characterized to unravel its role in predicting the graph signal, thereby enabling an interpretable GraphRC. Specifically, we first deduce the equivalence between the GraphRC and conventional reservoir computing (RC). Then, the underlying memory properties of the GraphRC and its reservoir nodes can be characterized in theory by the multisource reachability among the reservoir nodes in the transformed RC. Moreover, the distinct temporal patterns hidden in reservoir nodes are identified, and then, an attention mechanism based on the identified temporal patterns is deployed in the GraphRC to improve its performance. In addition, the effectiveness of the interpretability for GraphRC and improved GraphRC is verified on the Lorenz-96 spatiotemporal dynamical system. The experimental results of the Lorenz-96 spatiotemporal chaotic system and three real-world traffic datasets demonstrate that the improved GraphRC is superior to original GraphRC and can achieve prediction performance comparable to the state-of-the-art baseline models, but with much less training cost.
---
グラフ貯留計算（GraphRC）は、その高いトレーニング効率により、ますます注目を集めています。しかし、GraphRCはその内部メカニズムの知識なしに開発されているため、実際に展開するには完全に信頼できません。GraphRCを解釈するために拡張可能な既存のアプローチはいくつかありますが、GraphRCの各ニューロン（つまり、貯留ノード）が果たす具体的な役割はほとんど探求されていません。この問題に対処するために、GraphRCの各貯留ノードの潜在的な短期記憶特性を定性的に特徴付け、グラフ信号の予測におけるその役割を解明し、解釈可能なGraphRCを実現します。具体的には、まずGraphRCと従来の貯留計算（RC）との間の同等性を導出します。次に、変換されたRC内の貯留ノード間のマルチソース到達可能性によって、GraphRCおよびその貯留ノードの基礎となる記憶特性を理論的に特徴付けることができます。さらに、貯留ノードに隠された異なる時間パターンが特定され、その後、特定された時間パターンに基づく注意メカニズムがGraphRCに展開され、その性能を向上させます。加えて、GraphRCおよび改善されたGraphRCの解釈可能性の有効性は、Lorenz-96時空間動的システムで検証されます。Lorenz-96時空間カオスシステムおよび3つの実世界の交通データセットの実験結果は、改善されたGraphRCが元のGraphRCよりも優れており、最先端のベースラインモデルと同等の予測性能を達成できることを示していますが、トレーニングコストははるかに少ないです。

-
Anomalous event recognition requires an instant response to reduce the loss of human life and
property; however, existing automated systems show limited performance due to considerations
related to the temporal domain of the videos and ignore the significant role of spatial information.
Furthermore, although current surveillance systems can detect anomalous events, they require
human intervention to recognise their nature and to select appropriate countermeasures, as there
are no fully automatic surveillance techniques that can simultaneously detect and interpret
anomalous events. Therefore, we present a framework called Vision Transformer Anomaly
Recognition (ViT-ARN) that can detect and interpret anomalies in smart city surveillance videos.
The framework consists of two stages: the first involves online anomaly detection, for which a
customised, lightweight, one-class deep neural network is developed to detect anomalies in a
surveillance environment, while in the second stage, the detected anomaly is further classified
into the corresponding class. The size of our anomaly detection model is compressed using a filter
pruning strategy based on a geometric median, with the aim of easy adaptability for resourceconstrained devices. Anomaly classification is based on vision transformer features and is followed by a bottleneck attention mechanism to enhance the representation. The refined features
are passed to a multi-reservoir echo state network for a detailed analysis of real-world anomalies
such as vandalism and road accidents. A total of 858 and 1600 videos from two datasets are used
to train the proposed model, and extensive experiments on the LAD-2000 and UCF-Crime datasets
comprising 290 and 400 testing videos reveal that our framework can recognise anomalies more
effectively, outperforming other state-of-the-art approaches with increases in accuracy of 10.14%
and 3% on the LAD-2000 and UCF-Crime datasets, respectively. 
---
異常イベント認識は、人命と財産の損失を減らすために即時の対応が必要ですが、既存の自動化システムは動画の時間領域に関連する考慮事項により限られた性能を示し、空間情報の重要な役割を無視しています。さらに、現在の監視システムは異常イベントを検出できますが、その性質を認識し、適切な対策を選択するためには人間の介入が必要です。これは、異常イベントを同時に検出および解釈できる完全自動監視技術がないためです。したがって、スマートシティ監視動画で異常を検出および解釈できる「Vision Transformer Anomaly Recognition（ViT-ARN）」というフレームワークを提案します。このフレームワークは2つの段階で構成されています。最初の段階では、監視環境で異常を検出するためにカスタマイズされた軽量の一クラス深層ニューラルネットワークが開発されます。2番目の段階では、検出された異常が対応するクラスにさらに分類されます。異常検出モデルのサイズは、幾何学的中央値に基づくフィルタープルーニング戦略を使用して圧縮され、リソース制約のあるデバイスへの適応性を容易にします。異常分類はビジョントランスフォーマー特徴に基づき、その後ボトルネックアテンションメカニズムによって表現が強化されます。洗練された特徴は、多貯留エコー状態ネットワークに渡され、破壊行為や交通事故などの実世界の異常の詳細な分析が行われます。提案モデルは2つのデータセットから858本と1600本の動画を使用してトレーニングされ、LAD-2000およびUCF-Crimeデータセットで290本と400本のテスト動画を含む広範な実験により、我々のフレームワークは異常をより効果的に認識でき、LAD-2000およびUCF-Crimeデータセットでそれぞれ10.14%および3%の精度向上を達成し、他の最先端技術を上回ることが明らかになりました。
---

Although the attention mechanism in transformers has proven successful in image-text retrieval tasks, most transformer models suffer
from a large number of parameters. Inspired by brain circuits that
process information with recurrent connected neurons, we propose
a novel Reservoir Computing Transformer Reasoning Network
(RCTRN) for image-text retrieval. The proposed RCTRN employs a
two-step strategy to focus on feature representation and data distribution of different modalities respectively. Specifically, we send
visual and textual features through a unified meshed reasoning
module, which encodes multi-level feature relationships with prior
knowledge and aggregates the complementary outputs in a more
effective way. The reservoir reasoning network is proposed to optimize memory connections between features at different stages and
address the data distribution mismatch problem introduced by the
unified scheme. To investigate the significance of the low power
dissipation and low bandwidth characteristics of RRN in practical scenarios, we deployed the model in the wireless transmission
system, demonstrating that RRN’s optimization of data structures
also has a certain robustness against channel noise. Extensive experiments on two benchmark datasets, Flickr30K and MS-COCO,
demonstrate the superiority of RCTRN in terms of performance
and low-power dissipation compared to state-of-the-art baselines.
---
トランスフォーマーの注意メカニズムは画像-テキスト検索タスクで成功を収めていますが、ほとんどのトランスフォーマーモデルは多数のパラメータを抱えています。情報を再帰的に接続されたニューロンで処理する脳回路に触発され、画像-テキスト検索のための新しいリザーバーコンピューティングトランスフォーマー推論ネットワーク（RCTRN）を提案します。提案するRCTRNは、異なるモダリティの特徴表現とデータ分布にそれぞれ焦点を当てるための二段階戦略を採用しています。具体的には、視覚的およびテキストの特徴を統一されたメッシュ推論モジュールに送信し、事前知識を用いて多層の特徴関係をエンコードし、補完的な出力をより効果的に集約します。リザーバー推論ネットワークは、異なる段階での特徴間のメモリー接続を最適化し、統一されたスキームによって導入されるデータ分布の不一致問題に対処するために提案されます。実際のシナリオにおけるRRNの低電力消費と低帯域幅特性の重要性を調査するために、モデルを無線伝送システムに展開し、RRNのデータ構造の最適化がチャネルノイズに対しても一定の堅牢性を持つことを示しました。Flickr30KとMS-COCOの2つのベンチマークデータセットでの広範な実験により、最先端のベースラインと比較して、性能と低電力消費の点でRCTRNの優位性が実証されました。
---

In another line of work, it has been shown that neural networks with random weights, e.g. echo state networks [26] and
extreme learning machines [27], can have surprisingly powerful capabilities [28]. These findings have also been shown to
translate to automatic speech recognition tasks [29].

---
別の研究では、ランダムな重みを持つニューラルネットワーク、例えばエコー状態ネットワーク[26]や極端な学習マシン[27]が、驚くほど強力な能力を持つことが示されています[28]。これらの発見は、自動音声認識タスクにも適用できることが示されています[29]。

-

On top of compact architectural design, other compression
techniques may be used to further improve model efficiency.
While pruning [20] attempts to find and remove unimportant
weights, neurons, or layers, factorization [21] compresses the
weights using a low-dimensional approximation, and quantization [22, 23] allows one to store and perform operations in lowbit precision reducing the computational cost significantly [24].
Considering ternary weights, e.g. {−1, 0, 1}, multiplications
are reduced to bit-wise, sparse operations in hardware, which
are far less costly in terms of energy, speed, and area [25].

---
コンパクトなアーキテクチャ設計に加えて、他の圧縮技術を使用してモデルの効率をさらに向上させることができます。プルーニング[20]は重要でない重み、ニューロン、またはレイヤーを見つけて削除しようとする一方で、因子分解[21]は低次元近似を使用して重みを圧縮し、量子化[22, 23]は低ビット精度で保存および操作を行うことを可能にし、計算コストを大幅に削減します[24]。三元重み、例えば{−1, 0, 1}を考慮すると、乗算はハードウェアでビット単位のスパース操作に減少し、エネルギー、速度、および面積の点ではるかにコストがかからなくなります[25]。

-

Similar to echo state networks [26], a sufficient routing capacity is enabled by having trained layers before and after the
constant random ternary layers. This matches existing observations [25, 22], where starting quantization too early in the network degrades performance. With this in mind, we only ternarize and do not update the weights in the 1x1-convolutions inside
the residual blocks (which possess the majority of the weights).
Since the weights of the preceding temporal-convolution and
the subsequent batch normalization layers are still updated, a
scaling of the inputs and outputs may be learned, respectively.
---
エコー状態ネットワーク[26]と同様に、定数ランダム三元レイヤーの前後にトレーニングされたレイヤーを持つことで、十分なルーティング容量が可能になります。これは、ネットワーク内で量子化を早すぎる段階で開始すると性能が低下するという既存の観察結果[25, 22]と一致します。このことを念頭に置いて、残差ブロック内の1x1畳み込みの重みは三元化されますが、更新は行いません（これらの重みが大部分を占めています）。前の時間畳み込みおよび後続のバッチ正規化レイヤーの重みはまだ更新されているため、それぞれ入力と出力のスケーリングが学習される可能性があります。

-

By analyzing the weights of the 1x1-convolutions in the sequence of residual blocks, we observe that they do not expose
any obvious visual structure. Specifically, after applying trained
ternarized quantization (TTQ [25]), the resulting trained matrices maintain model performance even though they can hardly
be distinguished from random ternary matrices (see Figure 1).
---
残差ブロックのシーケンス内の1x1畳み込みの重みを分析することで、明らかな視覚構造を示さないことがわかります。具体的には、トレーニングされた三元化量子化（TTQ [25]）を適用した後、結果として得られるトレーニング済み行列は、ランダムな三元行列とほとんど区別がつかないにもかかわらず、モデルの性能を維持します（図1を参照）。

-

As previously mentioned, neural networks with random
weights show powerful capabilities [26, 27, 30]. Therefore,
we propose to use random ternarized matrices for the 1x1-
convolutions in the residual blocks by keeping them constant
while training the rest of the network. For each neuron, the
ternarized weights simply compute a scaled difference of sums
where the set I
+ contains all the indices of the connections with
the weight +1 and I
− contains all the indices of the connections
with the weight −1. The union I := I
− ∪I
+ may be sparse, i.e.
may not contain the indices of all neurons in the previous layer.
This scaled sum is a far cheaper operation than the traditional
floating-point matrix multiplication.
---
前述のように、ランダムな重みを持つニューラルネットワークは強力な能力を示します[26, 27, 30]。したがって、残差ブロックの1x1畳み込みにランダムな三元化行列を使用し、ネットワークの残りの部分をトレーニングしながらそれらを一定に保つことを提案します。各ニューロンに対して、三元化された重みは、重みが+1の接続のインデックスを含む集合I
+と、重みが−1の接続のインデックスを含む集合I
−の和のスケーリングされた差を計算します。集合I := I
− ∪I
+はスパースである可能性があり、つまり前の層のすべてのニューロンのインデックスを含まない場合があります。このスケーリングされた和は、従来の浮動小数点行列乗算よりもはるかに安価な操作です。  

-

Deploying Large Language Models (LLMs) efficiently on edge devices is often constrained by limited memory
capacity and high power consumption. Low-bit quantization
methods, particularly ternary quantization, have demonstrated
significant potential in preserving model accuracy while substantially decreasing memory footprint and computational costs.
However, existing general-purpose architectures and accelerators
have not fully exploited the advantages of low-bit quantization
due to insufficient specialized hardware support.
We introduce TerEffic, an FPGA-based architecture tailored
for ternary-quantized LLM inference. The proposed system
offers flexibility through reconfigurable hardware to meet various
system requirements. We evaluated two representative configurations: a fully on-chip design that stores all weights within
on-chip memories, scaling out using multiple FPGAs, and an
HBM-assisted design capable of accommodating larger models
on a single FPGA board.
Experimental results demonstrate significant performance and
energy efficiency improvements. For single-batch inference on a
370 M-parameter model, our fully on-chip architecture achieves
16,300 tokens/second, delivering a throughput 192× higher than
NVIDIA Jetson Orin Nano with a power efficiency of 455 tokens/second/W, marking a 19× improvement. The HBM-assisted
architecture processes 727 tokens/second for a larger 2.7Bparameter model—3× the throughput of NVIDIA A100—while
consuming only 46W, resulting in a power efficiency of 16
tokens/second/W, an 8× improvement over the A100.
---
大規模言語モデル（LLM）をエッジデバイスで効率的に展開することは、限られたメモリ容量と高い電力消費によって制約されることがよくあります。低ビット量子化手法、特に三元量子化は、モデルの精度を維持しながら、メモリフットプリントと計算コストを大幅に削減する可能性を示しています。しかし、既存の汎用アーキテクチャとアクセラレータは、専門的なハードウェアサポートが不十分なため、低ビット量子化の利点を十分に活用していません。
本研究では、三元量子化されたLLM推論のために特別に設計されたFPGAベースのアーキテクチャ「TerEffic」を紹介します。提案されたシステムは、さまざまなシステム要件を満たすために再構成可能なハードウェアを通じて柔軟性を提供します。2つの代表的な構成を評価しました。完全にオンチップ設計は、すべての重みをオンチップメモリに格納し、複数のFPGAを使用してスケーリングし、HBM支援設計は、単一のFPGAボード上でより大きなモデルを収容できるようにします。
実験結果は、性能とエネルギー効率の大幅な改善を示しています。370 Mパラメータモデルの単一バッチ推論では、完全にオンチップアーキテクチャが16,300トークン/秒を達成し、NVIDIA Jetson Orin Nanoのスループットを192倍、電力効率は455トークン/秒/Wを実現し、19倍の改善を示しました。HBM支援アーキテクチャは、より大きな2.7Bパラメータモデルに対して727トークン/秒を処理し、NVIDIA A100のスループットの3倍を達成し、消費電力はわずか46Wで、電力効率は16トークン/秒/Wとなり、A100に対して8倍の改善を実現しました。
-

